{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LoRA trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#makes a metadata.csv file to create the dataset\n",
    "import os\n",
    "labels = {}\n",
    "dataset_path = \"loras/hu_tao/dataset\"\n",
    "labels_paths = dataset_path + '/labels'\n",
    "for file in os.listdir(labels_paths):\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(os.path.join(labels_paths, file), 'r') as f:\n",
    "            name = file.split(\".\")[0] + \".jpg\"\n",
    "            labels[name] = f.read()\n",
    "\n",
    "metadata = 'file_name,text\\n'\n",
    "for k, v in labels.items():\n",
    "    metadata += f'{k},\"{v}\"\\n'\n",
    "with open(dataset_path + \"/metadata.csv\", \"w\") as f:\n",
    "    f.write(metadata)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 101/101 [00:00<00:00, 100935.12it/s]\n",
      "Map: 100%|██████████| 50/50 [00:00<00:00, 5063.63 examples/s]?it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 999.83ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.76s/it]\n"
     ]
    }
   ],
   "source": [
    "#requires to upload the dataset to the huggingface hub\n",
    "#huggingface-cli login has to be executed before running this code\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name = \"hu-tao-v2\"\n",
    "dataset = load_dataset('imagefolder', data_dir='loras/hu_tao/dataset')\n",
    "dataset.push_to_hub(dataset_name, private = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image', 'text']\n"
     ]
    }
   ],
   "source": [
    "dataset[\"train\"][2]['image']\t\n",
    "print(dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image', 'text']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/13/2023 23:02:00 - INFO - __main__ - Distributed environment: DistributedType.NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: fp16\n",
      "\n",
      "{'thresholding', 'timestep_spacing', 'prediction_type', 'sample_max_value', 'clip_sample_range', 'dynamic_thresholding_ratio', 'variance_type'} was not found in config. Values will be initialized to default values.\n",
      "{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "{'use_linear_projection', 'time_embedding_type', 'time_embedding_dim', 'dual_cross_attention', 'cross_attention_norm', 'time_cond_proj_dim', 'class_embed_type', 'conv_in_kernel', 'encoder_hid_dim_type', 'reverse_transformer_layers_per_block', 'addition_embed_type_num_heads', 'num_attention_heads', 'addition_time_embed_dim', 'resnet_out_scale_factor', 'mid_block_type', 'encoder_hid_dim', 'resnet_time_scale_shift', 'transformer_layers_per_block', 'only_cross_attention', 'time_embedding_act_fn', 'resnet_skip_time_act', 'conv_out_kernel', 'addition_embed_type', 'upcast_attention', 'timestep_post_act', 'mid_block_only_cross_attention', 'attention_type', 'num_class_embeds', 'class_embeddings_concat', 'projection_class_embeddings_input_dim', 'dropout'} was not found in config. Values will be initialized to default values.\n",
      "12/13/2023 23:02:12 - INFO - __main__ - ***** Running training *****\n",
      "12/13/2023 23:02:12 - INFO - __main__ -   Num examples = 50\n",
      "12/13/2023 23:02:12 - INFO - __main__ -   Num Epochs = 1154\n",
      "12/13/2023 23:02:12 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "12/13/2023 23:02:12 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "12/13/2023 23:02:12 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
      "12/13/2023 23:02:12 - INFO - __main__ -   Total optimization steps = 15000\n",
      "\n",
      "Steps:   0%|          | 0/15000 [00:00<?, ?it/s]C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\diffusers\\models\\attention_processor.py:1871: FutureWarning: `LoRAAttnProcessor` is deprecated and will be removed in version 0.26.0. Make sure use AttnProcessor instead by settingLoRA layers to `self.{to_q,to_k,to_v,to_out[0]}.lora_layer` respectively. This will be done automatically when using `LoraLoaderMixin.load_lora_weights`\n",
      "  deprecate(\n",
      "\n",
      "Steps:   0%|          | 0/15000 [00:02<?, ?it/s, lr=0.0001, step_loss=0.00958]\n",
      "Steps:   0%|          | 0/15000 [00:02<?, ?it/s, lr=0.0001, step_loss=0.042]  \n",
      "Steps:   0%|          | 0/15000 [00:02<?, ?it/s, lr=0.0001, step_loss=0.475]\n",
      "Steps:   0%|          | 1/15000 [00:02<11:16:36,  2.71s/it, lr=0.0001, step_loss=0.475]\n",
      "Steps:   0%|          | 1/15000 [00:02<11:16:36,  2.71s/it, lr=0.0001, step_loss=0.0111]\n",
      "Steps:   0%|          | 1/15000 [00:02<11:16:36,  2.71s/it, lr=0.0001, step_loss=0.289] \n",
      "Steps:   0%|          | 1/15000 [00:03<11:16:36,  2.71s/it, lr=0.0001, step_loss=0.0315]\n",
      "Steps:   0%|          | 1/15000 [00:03<11:16:36,  2.71s/it, lr=0.0001, step_loss=0.75]  \n",
      "Steps:   0%|          | 2/15000 [00:03<6:22:21,  1.53s/it, lr=0.0001, step_loss=0.75] \n",
      "Steps:   0%|          | 2/15000 [00:03<6:22:21,  1.53s/it, lr=0.0001, step_loss=0.118]\n",
      "Steps:   0%|          | 2/15000 [00:03<6:22:21,  1.53s/it, lr=0.0001, step_loss=0.00794]\n",
      "Steps:   0%|          | 2/15000 [00:03<6:22:21,  1.53s/it, lr=0.0001, step_loss=0.0593] \n",
      "Steps:   0%|          | 2/15000 [00:03<6:22:21,  1.53s/it, lr=0.0001, step_loss=0.348] \n",
      "Steps:   0%|          | 3/15000 [00:04<4:47:56,  1.15s/it, lr=0.0001, step_loss=0.348]\n",
      "Steps:   0%|          | 3/15000 [00:04<4:47:56,  1.15s/it, lr=0.0001, step_loss=0.0933]\n",
      "Steps:   0%|          | 3/15000 [00:04<4:47:56,  1.15s/it, lr=0.0001, step_loss=0.0899]\n",
      "Steps:   0%|          | 3/15000 [00:04<4:47:56,  1.15s/it, lr=0.0001, step_loss=0.0188]\n",
      "Steps:   0%|          | 3/15000 [00:04<4:47:56,  1.15s/it, lr=0.0001, step_loss=0.0721]\n",
      "Steps:   0%|          | 4/15000 [00:04<4:10:42,  1.00s/it, lr=0.0001, step_loss=0.0721]\n",
      "Steps:   0%|          | 4/15000 [00:04<4:10:42,  1.00s/it, lr=0.0001, step_loss=0.761] \n",
      "Steps:   0%|          | 4/15000 [00:05<4:10:42,  1.00s/it, lr=0.0001, step_loss=0.00954]\n",
      "Steps:   0%|          | 4/15000 [00:05<4:10:42,  1.00s/it, lr=0.0001, step_loss=0.00529]\n",
      "Steps:   0%|          | 4/15000 [00:05<4:10:42,  1.00s/it, lr=0.0001, step_loss=0.369]  \n",
      "Steps:   0%|          | 5/15000 [00:05<3:44:26,  1.11it/s, lr=0.0001, step_loss=0.369]\n",
      "Steps:   0%|          | 5/15000 [00:05<3:44:26,  1.11it/s, lr=0.0001, step_loss=0.0647]\n",
      "Steps:   0%|          | 5/15000 [00:05<3:44:26,  1.11it/s, lr=0.0001, step_loss=0.316] \n",
      "Steps:   0%|          | 5/15000 [00:05<3:44:26,  1.11it/s, lr=0.0001, step_loss=0.0479]\n",
      "Steps:   0%|          | 5/15000 [00:06<3:44:26,  1.11it/s, lr=0.0001, step_loss=0.423] \n",
      "Steps:   0%|          | 6/15000 [00:06<3:26:51,  1.21it/s, lr=0.0001, step_loss=0.423]\n",
      "Steps:   0%|          | 6/15000 [00:06<3:26:51,  1.21it/s, lr=0.0001, step_loss=0.0512]\n",
      "Steps:   0%|          | 6/15000 [00:06<3:26:51,  1.21it/s, lr=0.0001, step_loss=0.147] \n",
      "Steps:   0%|          | 6/15000 [00:06<3:26:51,  1.21it/s, lr=0.0001, step_loss=0.325]\n",
      "Steps:   0%|          | 6/15000 [00:06<3:26:51,  1.21it/s, lr=0.0001, step_loss=0.00951]\n",
      "Steps:   0%|          | 7/15000 [00:06<3:15:59,  1.27it/s, lr=0.0001, step_loss=0.00951]\n",
      "Steps:   0%|          | 7/15000 [00:06<3:15:59,  1.27it/s, lr=0.0001, step_loss=0.0855] \n",
      "Steps:   0%|          | 7/15000 [00:07<3:15:59,  1.27it/s, lr=0.0001, step_loss=0.282] \n",
      "Steps:   0%|          | 7/15000 [00:07<3:15:59,  1.27it/s, lr=0.0001, step_loss=0.157]\n",
      "Steps:   0%|          | 7/15000 [00:07<3:15:59,  1.27it/s, lr=0.0001, step_loss=0.125]\n",
      "Steps:   0%|          | 8/15000 [00:07<3:09:28,  1.32it/s, lr=0.0001, step_loss=0.125]\n",
      "Steps:   0%|          | 8/15000 [00:07<3:09:28,  1.32it/s, lr=0.0001, step_loss=0.0998]\n",
      "Steps:   0%|          | 8/15000 [00:07<3:09:28,  1.32it/s, lr=0.0001, step_loss=0.03]  \n",
      "Steps:   0%|          | 8/15000 [00:08<3:09:28,  1.32it/s, lr=0.0001, step_loss=0.221]\n",
      "Steps:   0%|          | 8/15000 [00:08<3:09:28,  1.32it/s, lr=0.0001, step_loss=0.072]\n",
      "Steps:   0%|          | 9/15000 [00:08<3:05:18,  1.35it/s, lr=0.0001, step_loss=0.072]\n",
      "Steps:   0%|          | 9/15000 [00:08<3:05:18,  1.35it/s, lr=0.0001, step_loss=0.074]\n",
      "Steps:   0%|          | 9/15000 [00:08<3:05:18,  1.35it/s, lr=0.0001, step_loss=0.802]\n",
      "Steps:   0%|          | 9/15000 [00:08<3:05:18,  1.35it/s, lr=0.0001, step_loss=0.511]\n",
      "Steps:   0%|          | 9/15000 [00:08<3:05:18,  1.35it/s, lr=0.0001, step_loss=0.00268]\n",
      "Steps:   0%|          | 10/15000 [00:09<3:02:47,  1.37it/s, lr=0.0001, step_loss=0.00268]\n",
      "Steps:   0%|          | 10/15000 [00:09<3:02:47,  1.37it/s, lr=0.0001, step_loss=0.00369]\n",
      "Steps:   0%|          | 10/15000 [00:09<3:02:47,  1.37it/s, lr=0.0001, step_loss=0.373]  \n",
      "Steps:   0%|          | 10/15000 [00:09<3:02:47,  1.37it/s, lr=0.0001, step_loss=0.0776]\n",
      "Steps:   0%|          | 10/15000 [00:09<3:02:47,  1.37it/s, lr=0.0001, step_loss=0.299] \n",
      "Steps:   0%|          | 11/15000 [00:09<2:59:43,  1.39it/s, lr=0.0001, step_loss=0.299]\n",
      "Steps:   0%|          | 11/15000 [00:09<2:59:43,  1.39it/s, lr=0.0001, step_loss=0.00805]\n",
      "Steps:   0%|          | 11/15000 [00:09<2:59:43,  1.39it/s, lr=0.0001, step_loss=0.00987]\n",
      "Steps:   0%|          | 11/15000 [00:10<2:59:43,  1.39it/s, lr=0.0001, step_loss=0.03]   \n",
      "Steps:   0%|          | 11/15000 [00:10<2:59:43,  1.39it/s, lr=0.0001, step_loss=0.0966]\n",
      "Steps:   0%|          | 12/15000 [00:10<2:58:13,  1.40it/s, lr=0.0001, step_loss=0.0966]\n",
      "Steps:   0%|          | 12/15000 [00:10<2:58:13,  1.40it/s, lr=0.0001, step_loss=0.0571]\n",
      "Steps:   0%|          | 12/15000 [00:10<2:58:13,  1.40it/s, lr=0.0001, step_loss=0.422] \n",
      "Steps:   0%|          | 13/15000 [00:10<2:30:09,  1.66it/s, lr=0.0001, step_loss=0.422]\n",
      "Steps:   0%|          | 13/15000 [00:10<2:30:09,  1.66it/s, lr=0.0001, step_loss=0.00297]12/13/2023 23:02:23 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: 1 girl, hu tao, genshin impact, forest, spear.\n",
      "{'image_encoder', 'requires_safety_checker'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "\n",
      "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]\u001b[A`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n",
      "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "\n",
      "\n",
      "Loading pipeline components...:  14%|█▍        | 1/7 [00:01<00:09,  1.53s/it]\u001b[ALoaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "Loaded text_encoder as CLIPTextModel from `text_encoder` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "\n",
      "\n",
      "Loading pipeline components...:  57%|█████▋    | 4/7 [00:01<00:01,  2.42it/s]\u001b[A{'scaling_factor', 'force_upcast'} was not found in config. Values will be initialized to default values.\n",
      "Loaded vae as AutoencoderKL from `vae` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "\n",
      "\n",
      "Loading pipeline components...:  71%|███████▏  | 5/7 [00:02<00:00,  2.83it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of runwayml/stable-diffusion-v1-5.\n",
      "\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  3.11it/s]\n",
      "\n",
      "Steps:   0%|          | 13/15000 [00:25<2:30:09,  1.66it/s, lr=0.0001, step_loss=0.062]  \n",
      "Steps:   0%|          | 13/15000 [00:25<2:30:09,  1.66it/s, lr=0.0001, step_loss=0.0606]\n",
      "Steps:   0%|          | 13/15000 [00:25<2:30:09,  1.66it/s, lr=0.0001, step_loss=0.149] \n",
      "Steps:   0%|          | 14/15000 [00:25<20:31:03,  4.93s/it, lr=0.0001, step_loss=0.149]\n",
      "Steps:   0%|          | 14/15000 [00:25<20:31:03,  4.93s/it, lr=0.0001, step_loss=0.0162]\n",
      "Steps:   0%|          | 14/15000 [00:25<20:31:03,  4.93s/it, lr=0.0001, step_loss=0.0728]\n",
      "Steps:   0%|          | 14/15000 [00:26<20:31:03,  4.93s/it, lr=0.0001, step_loss=0.31]  \n",
      "Steps:   0%|          | 14/15000 [00:26<20:31:03,  4.93s/it, lr=0.0001, step_loss=0.0181]\n",
      "Steps:   0%|          | 15/15000 [00:26<15:13:16,  3.66s/it, lr=0.0001, step_loss=0.0181]\n",
      "Steps:   0%|          | 15/15000 [00:26<15:13:16,  3.66s/it, lr=0.0001, step_loss=0.0171]\n",
      "Steps:   0%|          | 15/15000 [00:26<15:13:16,  3.66s/it, lr=0.0001, step_loss=0.298] \n",
      "Steps:   0%|          | 15/15000 [00:26<15:13:16,  3.66s/it, lr=0.0001, step_loss=0.131]\n",
      "Steps:   0%|          | 15/15000 [00:26<15:13:16,  3.66s/it, lr=0.0001, step_loss=0.0138]\n",
      "Steps:   0%|          | 16/15000 [00:27<11:29:45,  2.76s/it, lr=0.0001, step_loss=0.0138]\n",
      "Steps:   0%|          | 16/15000 [00:27<11:29:45,  2.76s/it, lr=0.0001, step_loss=0.0836]\n",
      "Steps:   0%|          | 16/15000 [00:27<11:29:45,  2.76s/it, lr=0.0001, step_loss=0.338] \n",
      "Steps:   0%|          | 16/15000 [00:27<11:29:45,  2.76s/it, lr=0.0001, step_loss=0.00374]\n",
      "Steps:   0%|          | 16/15000 [00:27<11:29:45,  2.76s/it, lr=0.0001, step_loss=0.281]  \n",
      "Steps:   0%|          | 17/15000 [00:27<8:54:38,  2.14s/it, lr=0.0001, step_loss=0.281] \n",
      "Steps:   0%|          | 17/15000 [00:27<8:54:38,  2.14s/it, lr=0.0001, step_loss=0.00403]\n",
      "Steps:   0%|          | 17/15000 [00:28<8:54:38,  2.14s/it, lr=0.0001, step_loss=0.115]  \n",
      "Steps:   0%|          | 17/15000 [00:28<8:54:38,  2.14s/it, lr=0.0001, step_loss=0.259]\n",
      "Steps:   0%|          | 17/15000 [00:28<8:54:38,  2.14s/it, lr=0.0001, step_loss=0.0293]\n",
      "Steps:   0%|          | 18/15000 [00:28<7:04:22,  1.70s/it, lr=0.0001, step_loss=0.0293]\n",
      "Steps:   0%|          | 18/15000 [00:28<7:04:22,  1.70s/it, lr=0.0001, step_loss=0.0248]\n",
      "Steps:   0%|          | 18/15000 [00:28<7:04:22,  1.70s/it, lr=0.0001, step_loss=0.00556]\n",
      "Steps:   0%|          | 18/15000 [00:28<7:04:22,  1.70s/it, lr=0.0001, step_loss=0.034]  \n",
      "Steps:   0%|          | 18/15000 [00:29<7:04:22,  1.70s/it, lr=0.0001, step_loss=0.15] \n",
      "Steps:   0%|          | 19/15000 [00:29<5:46:16,  1.39s/it, lr=0.0001, step_loss=0.15]\n",
      "Steps:   0%|          | 19/15000 [00:29<5:46:16,  1.39s/it, lr=0.0001, step_loss=0.101]\n",
      "Steps:   0%|          | 19/15000 [00:29<5:46:16,  1.39s/it, lr=0.0001, step_loss=0.0645]\n",
      "Steps:   0%|          | 19/15000 [00:29<5:46:16,  1.39s/it, lr=0.0001, step_loss=0.139] \n",
      "Steps:   0%|          | 19/15000 [00:29<5:46:16,  1.39s/it, lr=0.0001, step_loss=0.0395]\n",
      "Steps:   0%|          | 20/15000 [00:29<4:51:47,  1.17s/it, lr=0.0001, step_loss=0.0395]\n",
      "Steps:   0%|          | 20/15000 [00:29<4:51:47,  1.17s/it, lr=0.0001, step_loss=0.418] \n",
      "Steps:   0%|          | 20/15000 [00:30<4:51:47,  1.17s/it, lr=0.0001, step_loss=0.359]\n",
      "Steps:   0%|          | 20/15000 [00:30<4:51:47,  1.17s/it, lr=0.0001, step_loss=0.0843]\n",
      "Steps:   0%|          | 20/15000 [00:30<4:51:47,  1.17s/it, lr=0.0001, step_loss=0.0237]\n",
      "Steps:   0%|          | 21/15000 [00:30<4:15:12,  1.02s/it, lr=0.0001, step_loss=0.0237]\n",
      "Steps:   0%|          | 21/15000 [00:30<4:15:12,  1.02s/it, lr=0.0001, step_loss=0.431] \n",
      "Steps:   0%|          | 21/15000 [00:30<4:15:12,  1.02s/it, lr=0.0001, step_loss=0.00659]\n",
      "Steps:   0%|          | 21/15000 [00:30<4:15:12,  1.02s/it, lr=0.0001, step_loss=0.0206] \n",
      "Steps:   0%|          | 21/15000 [00:31<4:15:12,  1.02s/it, lr=0.0001, step_loss=0.106] \n",
      "Steps:   0%|          | 22/15000 [00:31<3:46:48,  1.10it/s, lr=0.0001, step_loss=0.106]\n",
      "Steps:   0%|          | 22/15000 [00:31<3:46:48,  1.10it/s, lr=0.0001, step_loss=0.0725]\n",
      "Steps:   0%|          | 22/15000 [00:31<3:46:48,  1.10it/s, lr=0.0001, step_loss=0.00832]\n",
      "Steps:   0%|          | 22/15000 [00:31<3:46:48,  1.10it/s, lr=0.0001, step_loss=0.0225] \n",
      "Steps:   0%|          | 22/15000 [00:31<3:46:48,  1.10it/s, lr=0.0001, step_loss=0.0763]\n",
      "Steps:   0%|          | 23/15000 [00:31<3:27:25,  1.20it/s, lr=0.0001, step_loss=0.0763]\n",
      "Steps:   0%|          | 23/15000 [00:31<3:27:25,  1.20it/s, lr=0.0001, step_loss=0.00578]\n",
      "Steps:   0%|          | 23/15000 [00:31<3:27:25,  1.20it/s, lr=0.0001, step_loss=0.00546]\n",
      "Steps:   0%|          | 23/15000 [00:32<3:27:25,  1.20it/s, lr=0.0001, step_loss=0.0738] \n",
      "Steps:   0%|          | 23/15000 [00:32<3:27:25,  1.20it/s, lr=0.0001, step_loss=0.391] \n",
      "Steps:   0%|          | 24/15000 [00:32<3:13:58,  1.29it/s, lr=0.0001, step_loss=0.391]\n",
      "Steps:   0%|          | 24/15000 [00:32<3:13:58,  1.29it/s, lr=0.0001, step_loss=0.479]\n",
      "Steps:   0%|          | 24/15000 [00:32<3:13:58,  1.29it/s, lr=0.0001, step_loss=0.479]\n",
      "Steps:   0%|          | 24/15000 [00:32<3:13:58,  1.29it/s, lr=0.0001, step_loss=0.221]\n",
      "Steps:   0%|          | 24/15000 [00:32<3:13:58,  1.29it/s, lr=0.0001, step_loss=0.00397]\n",
      "Steps:   0%|          | 25/15000 [00:33<3:05:10,  1.35it/s, lr=0.0001, step_loss=0.00397]\n",
      "Steps:   0%|          | 25/15000 [00:33<3:05:10,  1.35it/s, lr=0.0001, step_loss=0.229]  \n",
      "Steps:   0%|          | 25/15000 [00:33<3:05:10,  1.35it/s, lr=0.0001, step_loss=0.439]\n",
      "Steps:   0%|          | 26/15000 [00:33<2:34:55,  1.61it/s, lr=0.0001, step_loss=0.439]\n",
      "Steps:   0%|          | 26/15000 [00:33<2:34:55,  1.61it/s, lr=0.0001, step_loss=0.341]\n",
      "Steps:   0%|          | 26/15000 [00:33<2:34:55,  1.61it/s, lr=0.0001, step_loss=0.0476]\n",
      "Steps:   0%|          | 26/15000 [00:33<2:34:55,  1.61it/s, lr=0.0001, step_loss=0.0901]\n",
      "Steps:   0%|          | 26/15000 [00:33<2:34:55,  1.61it/s, lr=0.0001, step_loss=0.00555]\n",
      "Steps:   0%|          | 27/15000 [00:34<2:37:38,  1.58it/s, lr=0.0001, step_loss=0.00555]\n",
      "Steps:   0%|          | 27/15000 [00:34<2:37:38,  1.58it/s, lr=0.0001, step_loss=0.282]  \n",
      "Steps:   0%|          | 27/15000 [00:34<2:37:38,  1.58it/s, lr=0.0001, step_loss=0.193]\n",
      "Steps:   0%|          | 27/15000 [00:34<2:37:38,  1.58it/s, lr=0.0001, step_loss=0.0776]\n",
      "Steps:   0%|          | 27/15000 [00:34<2:37:38,  1.58it/s, lr=0.0001, step_loss=0.244] \n",
      "Steps:   0%|          | 28/15000 [00:34<2:40:00,  1.56it/s, lr=0.0001, step_loss=0.244]\n",
      "Steps:   0%|          | 28/15000 [00:34<2:40:00,  1.56it/s, lr=0.0001, step_loss=0.017]\n",
      "Steps:   0%|          | 28/15000 [00:34<2:40:00,  1.56it/s, lr=0.0001, step_loss=0.11] \n",
      "Steps:   0%|          | 28/15000 [00:35<2:40:00,  1.56it/s, lr=0.0001, step_loss=0.572]\n",
      "Steps:   0%|          | 28/15000 [00:35<2:40:00,  1.56it/s, lr=0.0001, step_loss=0.297]\n",
      "Steps:   0%|          | 29/15000 [00:35<2:43:17,  1.53it/s, lr=0.0001, step_loss=0.297]\n",
      "Steps:   0%|          | 29/15000 [00:35<2:43:17,  1.53it/s, lr=0.0001, step_loss=0.00567]\n",
      "Steps:   0%|          | 29/15000 [00:35<2:43:17,  1.53it/s, lr=0.0001, step_loss=0.641]  \n",
      "Steps:   0%|          | 29/15000 [00:35<2:43:17,  1.53it/s, lr=0.0001, step_loss=0.446]\n",
      "Steps:   0%|          | 29/15000 [00:36<2:43:17,  1.53it/s, lr=0.0001, step_loss=0.218]\n",
      "Steps:   0%|          | 30/15000 [00:36<2:46:43,  1.50it/s, lr=0.0001, step_loss=0.218]\n",
      "Steps:   0%|          | 30/15000 [00:36<2:46:43,  1.50it/s, lr=0.0001, step_loss=0.117]\n",
      "Steps:   0%|          | 30/15000 [00:36<2:46:43,  1.50it/s, lr=0.0001, step_loss=0.00345]\n",
      "Steps:   0%|          | 30/15000 [00:36<2:46:43,  1.50it/s, lr=0.0001, step_loss=0.00624]\n",
      "Steps:   0%|          | 30/15000 [00:36<2:46:43,  1.50it/s, lr=0.0001, step_loss=0.165]  \n",
      "Steps:   0%|          | 31/15000 [00:36<2:53:54,  1.43it/s, lr=0.0001, step_loss=0.165]\n",
      "Steps:   0%|          | 31/15000 [00:36<2:53:54,  1.43it/s, lr=0.0001, step_loss=0.682]\n",
      "Steps:   0%|          | 31/15000 [00:37<2:53:54,  1.43it/s, lr=0.0001, step_loss=0.524]\n",
      "Steps:   0%|          | 31/15000 [00:37<2:53:54,  1.43it/s, lr=0.0001, step_loss=0.393]\n",
      "Steps:   0%|          | 31/15000 [00:37<2:53:54,  1.43it/s, lr=0.0001, step_loss=0.212]\n",
      "Steps:   0%|          | 32/15000 [00:37<2:56:46,  1.41it/s, lr=0.0001, step_loss=0.212]\n",
      "Steps:   0%|          | 32/15000 [00:37<2:56:46,  1.41it/s, lr=0.0001, step_loss=0.153]\n",
      "Steps:   0%|          | 32/15000 [00:37<2:56:46,  1.41it/s, lr=0.0001, step_loss=0.0921]\n",
      "Steps:   0%|          | 32/15000 [00:38<2:56:46,  1.41it/s, lr=0.0001, step_loss=0.00806]\n",
      "Steps:   0%|          | 32/15000 [00:38<2:56:46,  1.41it/s, lr=0.0001, step_loss=0.252]  \n",
      "Steps:   0%|          | 33/15000 [00:38<2:55:48,  1.42it/s, lr=0.0001, step_loss=0.252]\n",
      "Steps:   0%|          | 33/15000 [00:38<2:55:48,  1.42it/s, lr=0.0001, step_loss=0.0784]\n",
      "Steps:   0%|          | 33/15000 [00:38<2:55:48,  1.42it/s, lr=0.0001, step_loss=0.111] \n",
      "Steps:   0%|          | 33/15000 [00:38<2:55:48,  1.42it/s, lr=0.0001, step_loss=0.0317]\n",
      "Steps:   0%|          | 33/15000 [00:38<2:55:48,  1.42it/s, lr=0.0001, step_loss=0.562] \n",
      "Steps:   0%|          | 34/15000 [00:39<2:55:46,  1.42it/s, lr=0.0001, step_loss=0.562]Exception in thread Thread-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 194, in flush\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\XayEss\\Documents\\ML Project\\AI-character-gen\\train_text_to_image_lora.py\", line 928, in <module>\n",
      "    self._check_worker_status()\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 212, in _check_worker_status\n",
      "    main()\n",
      "  File \"c:\\Users\\XayEss\\Documents\\ML Project\\AI-character-gen\\train_text_to_image_lora.py\", line 791, in main\n",
      "    raise exception\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    accelerator.log({\"train_loss\": train_loss}, step=global_step)\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\accelerate\\accelerator.py\", line 619, in _inner\n",
      "    return PartialState().on_main_process(function)(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^    ^self.run()^^^^^^^^^^^\n",
      "^  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 244, in run\n",
      "^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\accelerate\\accelerator.py\", line 2399, in log\n",
      "    self._run()\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 275, in _run\n",
      "    tracker.log(values, step=step, **log_kwargs.get(tracker.name, {}))\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\accelerate\\tracking.py\", line 79, in execute_on_main_process\n",
      "    self._record_writer.write(data)\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py\", line 40, in write\n",
      "    return PartialState().on_main_process(function)(self, *args, **kwargs)\n",
      "      self._writer.write(header + header_crc + data + footer_crc) \n",
      "    File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 773, in write\n",
      "      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\accelerate\\tracking.py\", line 247, in log\n",
      "    self.writer.flush()\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\", line 1233, in flush\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 167, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 171, in _write\n",
      "    writer.flush()\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\", line 146, in flush\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: b'$lora_train\\\\loras\\\\hu_tao2\\\\logs\\\\text2image-fine-tune\\\\events.out.tfevents.1702526532.DESKTOP-2KMONV5.9784.0'\n",
      "    self.event_writer.flush()\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 125, in flush\n",
      "    self._async_writer.flush()\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 194, in flush\n",
      "    self._check_worker_status()\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 212, in _check_worker_status\n",
      "    raise exception\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\threading.py\", line 1038, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 244, in run\n",
      "    self._run()\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 275, in _run\n",
      "    self._record_writer.write(data)\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 773, in write\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 167, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 171, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: b'$lora_train\\\\loras\\\\hu_tao2\\\\logs\\\\text2image-fine-tune\\\\events.out.tfevents.1702526532.DESKTOP-2KMONV5.9784.0'\n",
      "\n",
      "Steps:   0%|          | 34/15000 [00:39<4:48:28,  1.16s/it, lr=0.0001, step_loss=0.562]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Scripts\\accelerate-script.py\", line 9, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\accelerate\\commands\\accelerate_cli.py\", line 47, in main\n",
      "    args.func(args)\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\accelerate\\commands\\launch.py\", line 1017, in launch_command\n",
      "    simple_launcher(args)\n",
      "  File \"C:\\Users\\XayEss\\anaconda3\\envs\\gpu\\Lib\\site-packages\\accelerate\\commands\\launch.py\", line 637, in simple_launcher\n",
      "    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['C:\\\\Users\\\\XayEss\\\\anaconda3\\\\envs\\\\gpu\\\\python.exe', 'train_text_to_image_lora.py', '--pretrained_model_name_or_path=runwayml/stable-diffusion-v1-5', '--dataset_name=XayEss/hu-tao-v2', '--dataloader_num_workers=0', '--resolution=512', '--center_crop', '--random_flip', '--train_batch_size=1', '--gradient_accumulation_steps=4', '--max_train_steps=15000', '--learning_rate=1e-04', '--max_grad_norm=1', '--lr_scheduler=cosine', '--lr_warmup_steps=0', '--output_dir=$lora_train/loras/hu_tao2', '--checkpointing_steps=1000', '--validation_prompt=1 girl, hu tao, genshin impact, forest, spear', '--seed=1337', '--validation_epochs=100']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\n",
    "OUTPUT_DIR=\"lora_train/loras/hu_tao2\"\n",
    "DATASET_NAME=\"XayEss/\" + dataset_name\n",
    "\n",
    "!accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py \\\n",
    "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
    "  --dataset_name=$DATASET_NAME \\\n",
    "  --dataloader_num_workers=0 \\\n",
    "  --resolution=512 \\\n",
    "  --center_crop \\\n",
    "  --random_flip \\\n",
    "  --train_batch_size=1 \\\n",
    "  --gradient_accumulation_steps=4 \\\n",
    "  --max_train_steps=15000 \\\n",
    "  --learning_rate=1e-04 \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler=\"cosine\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --output_dir=${OUTPUT_DIR} \\\n",
    "  --checkpointing_steps=1000 \\\n",
    "  --validation_prompt=\"1 girl, hu tao, genshin impact, forest, spear\" \\\n",
    "  --seed=1337 \\\n",
    "  --validation_epochs=100 \\\n",
    "  --rank=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accelerate launch --mixed_precision=\"fp16\"  train_text_to_image_lora.py --pretrained_model_name_or_path=\"runwayml/stable-diffusion-v1-5\" --dataset_name=\"XayEss/hu-tao-v2\" --dataloader_num_workers=0 --resolution=512 --center_crop --random_flip --train_batch_size=2 --gradient_accumulation_steps=4 --max_train_steps=15000 --learning_rate=1e-04 --max_grad_norm=1 --lr_scheduler=\"cosine\" --lr_warmup_steps=0 --output_dir=\"loras/hu_tao/lora\" --checkpointing_steps=1000 --validation_prompt=\"1 girl, hu tao, genshin impact, forest, spear\" --seed=1337 --validation_epochs=100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
